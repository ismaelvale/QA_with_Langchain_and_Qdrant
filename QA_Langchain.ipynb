{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Running 1/0\n",
      " \u001b[32m✔\u001b[0m Container qa_with_langchain_and_qdrant-qdrant-1  \u001b[32mRunning\u001b[0m                \u001b[34m0.0s \u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "! docker-compose up -d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"title\":\"qdrant - vector search engine\",\"version\":\"1.3.2\"}"
     ]
    }
   ],
   "source": [
    "! curl http://localhost:6333"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /opt/homebrew/lib/python3.11/site-packages (0.27.8)\n",
      "Requirement already satisfied: qdrant-client in /opt/homebrew/lib/python3.11/site-packages (1.4.0)\n",
      "Requirement already satisfied: langchain in /opt/homebrew/lib/python3.11/site-packages (0.0.252)\n",
      "Requirement already satisfied: wget in /opt/homebrew/lib/python3.11/site-packages (3.2)\n",
      "Requirement already satisfied: python-dotenv in /opt/homebrew/lib/python3.11/site-packages (1.0.0)\n",
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.4.0-cp311-cp311-macosx_11_0_arm64.whl (761 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m761.4/761.4 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.20 in /opt/homebrew/lib/python3.11/site-packages (from openai) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /opt/homebrew/lib/python3.11/site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: aiohttp in /opt/homebrew/lib/python3.11/site-packages (from openai) (3.8.5)\n",
      "Requirement already satisfied: grpcio>=1.41.0 in /opt/homebrew/lib/python3.11/site-packages (from qdrant-client) (1.56.2)\n",
      "Requirement already satisfied: grpcio-tools>=1.41.0 in /opt/homebrew/lib/python3.11/site-packages (from qdrant-client) (1.56.2)\n",
      "Requirement already satisfied: httpx[http2]>=0.14.0 in /opt/homebrew/lib/python3.11/site-packages (from qdrant-client) (0.24.1)\n",
      "Requirement already satisfied: numpy>=1.21 in /opt/homebrew/lib/python3.11/site-packages (from qdrant-client) (1.25.2)\n",
      "Requirement already satisfied: portalocker<3.0.0,>=2.7.0 in /opt/homebrew/lib/python3.11/site-packages (from qdrant-client) (2.7.0)\n",
      "Requirement already satisfied: pydantic>=1.10.8 in /opt/homebrew/lib/python3.11/site-packages (from qdrant-client) (1.10.12)\n",
      "Requirement already satisfied: urllib3<2.0.0,>=1.26.14 in /opt/homebrew/lib/python3.11/site-packages (from qdrant-client) (1.26.16)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/homebrew/lib/python3.11/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/homebrew/lib/python3.11/site-packages (from langchain) (2.0.19)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /opt/homebrew/lib/python3.11/site-packages (from langchain) (0.5.14)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.11 in /opt/homebrew/lib/python3.11/site-packages (from langchain) (0.0.19)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /opt/homebrew/lib/python3.11/site-packages (from langchain) (2.8.4)\n",
      "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /opt/homebrew/lib/python3.11/site-packages (from langchain) (1.2.4)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/homebrew/lib/python3.11/site-packages (from langchain) (8.2.2)\n",
      "Collecting regex>=2022.1.18 (from tiktoken)\n",
      "  Obtaining dependency information for regex>=2022.1.18 from https://files.pythonhosted.org/packages/f8/bc/01e6a5597904147d13c1a6dc16ec334b73cddb190b6b8f05fca2c0bfbe89/regex-2023.6.3-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading regex-2023.6.3-cp311-cp311-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp->openai) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp->openai) (3.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp->openai) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/homebrew/lib/python3.11/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/homebrew/lib/python3.11/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: protobuf<5.0dev,>=4.21.6 in /opt/homebrew/lib/python3.11/site-packages (from grpcio-tools>=1.41.0->qdrant-client) (4.23.4)\n",
      "Requirement already satisfied: setuptools in /opt/homebrew/lib/python3.11/site-packages (from grpcio-tools>=1.41.0->qdrant-client) (68.0.0)\n",
      "Requirement already satisfied: certifi in /opt/homebrew/lib/python3.11/site-packages (from httpx[http2]>=0.14.0->qdrant-client) (2023.7.22)\n",
      "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in /opt/homebrew/lib/python3.11/site-packages (from httpx[http2]>=0.14.0->qdrant-client) (0.17.3)\n",
      "Requirement already satisfied: idna in /opt/homebrew/lib/python3.11/site-packages (from httpx[http2]>=0.14.0->qdrant-client) (3.4)\n",
      "Requirement already satisfied: sniffio in /opt/homebrew/lib/python3.11/site-packages (from httpx[http2]>=0.14.0->qdrant-client) (1.3.0)\n",
      "Requirement already satisfied: h2<5,>=3 in /opt/homebrew/lib/python3.11/site-packages (from httpx[http2]>=0.14.0->qdrant-client) (4.1.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/homebrew/lib/python3.11/site-packages (from pydantic>=1.10.8->qdrant-client) (4.7.1)\n",
      "Requirement already satisfied: hyperframe<7,>=6.0 in /opt/homebrew/lib/python3.11/site-packages (from h2<5,>=3->httpx[http2]>=0.14.0->qdrant-client) (6.0.1)\n",
      "Requirement already satisfied: hpack<5,>=4.0 in /opt/homebrew/lib/python3.11/site-packages (from h2<5,>=3->httpx[http2]>=0.14.0->qdrant-client) (4.0.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/homebrew/lib/python3.11/site-packages (from httpcore<0.18.0,>=0.15.0->httpx[http2]>=0.14.0->qdrant-client) (0.14.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /opt/homebrew/lib/python3.11/site-packages (from httpcore<0.18.0,>=0.15.0->httpx[http2]>=0.14.0->qdrant-client) (3.7.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/ismaelvalentin/Library/Python/3.11/lib/python/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/homebrew/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n",
      "Downloading regex-2023.6.3-cp311-cp311-macosx_11_0_arm64.whl (288 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.0/289.0 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: regex, tiktoken\n",
      "Successfully installed regex-2023.6.3 tiktoken-0.4.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install openai qdrant-client langchain wget python-dotenv tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY is ready\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from os import environ\n",
    "env_file = '.env'\n",
    "load_dotenv(env_file, override=True)\n",
    "\n",
    "if environ.get(\"OPENAI_API_KEY\") is not None:\n",
    "    print(\"OPENAI_API_KEY is ready\")\n",
    "else:\n",
    "    print(\"OPENAI_API_KEY environment variable not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'answers.json'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wget\n",
    "\n",
    "wget.download(\"https://storage.googleapis.com/dataset-natural-questions/questions.json\")\n",
    "wget.download(\"https://storage.googleapis.com/dataset-natural-questions/answers.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"questions.json\", \"r\") as fp:\n",
    "    questions = json.load(fp)\n",
    "\n",
    "with open(\"answers.json\",\"r\") as fp:\n",
    "    answers = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when is the last episode of season 8 of the walking dead\n"
     ]
    }
   ],
   "source": [
    "print(questions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No . overall No. in season Title Directed by Written by Original air date U.S. viewers ( millions ) 100 `` Mercy '' Greg Nicotero Scott M. Gimple October 22 , 2017 ( 2017 - 10 - 22 ) 11.44 Rick , Maggie , and Ezekiel rally their communities together to take down Negan . Gregory attempts to have the Hilltop residents side with Negan , but they all firmly stand behind Maggie . The group attacks the Sanctuary , taking down its fences and flooding the compound with walkers . With the Sanctuary defaced , everyone leaves except Gabriel , who reluctantly stays to save Gregory , but is left behind when Gregory abandons him . Surrounded by walkers , Gabriel hides in a trailer , where he is trapped inside with Negan . 101 `` The Damned '' Rosemary Rodriguez Matthew Negrete & Channing Powell October 29 , 2017 ( 2017 - 10 - 29 ) 8.92 Rick 's forces split into separate parties to attack several of the Saviors ' outposts , during which many members of the group are killed ; Eric is critically injured and rushed away by Aaron . Jesus stops Tara and Morgan from executing a group of surrendered Saviors . While clearing an outpost with Daryl , Rick is confronted and held at gunpoint by Morales , a survivor he met in the initial Atlanta camp , who is now with the Saviors . 102 `` Monsters '' Greg Nicotero Matthew Negrete & Channing Powell November 5 , 2017 ( 2017 - 11 - 05 ) 8.52 Daryl finds Morales threatening Rick and kills him ; the duo then pursue a group of Saviors who are transporting weapons to another outpost . Gregory returns to Hilltop , and after a heated argument , Maggie ultimately allows him back in the community . Eric dies from his injuries , leaving Aaron distraught . Despite Tara and Morgan 's objections , Jesus leads the group of surrendered Saviors to Hilltop . Ezekiel 's group attacks another Savior compound , during which several Kingdommers are shot while protecting Ezekiel . 103 `` Some Guy '' Dan Liu David Leslie Johnson November 12 , 2017 ( 2017 - 11 - 12 ) 8.69 Ezekiel 's group is overwhelmed by the Saviors , who kill all of them except for Ezekiel himself and Jerry . Carol clears the inside of the compound , killing all but two Saviors , who almost escape but are eventually caught by Rick and Daryl . En route to the Kingdom , Ezekiel , Jerry , and Carol are surrounded by walkers , but Shiva sacrifices herself to save them . The trio returns to the Kingdom , where Ezekiel 's confidence in himself as a leader has diminished . 104 5 `` The Big Scary U '' Michael E. Satrazemis Story by : Scott M. Gimple & David Leslie Johnson & Angela Kang Teleplay by : David Leslie Johnson & Angela Kang November 19 , 2017 ( 2017 - 11 - 19 ) 7.85 After confessing their sins to each other , Gabriel and Negan manage to escape from the trailer . Simon and the other lieutenants grow suspicious of each other , knowing that Rick 's forces must have inside information . The workers in the Sanctuary become increasingly frustrated with their living conditions , and a riot nearly ensues , until Negan returns and restores order . Gabriel is locked in a cell , where Eugene discovers him sick and suffering . Meanwhile , Rick and Daryl argue over how to take out the Saviors , leading Daryl to abandon Rick . 105 6 `` The King , the Widow , and Rick '' John Polson Angela Kang & Corey Reed November 26 , 2017 ( 2017 - 11 - 26 ) 8.28 Rick visits Jadis in hopes of convincing her to turn against Negan ; Jadis refuses , and locks Rick in a shipping container . Carl encounters Siddiq in the woods and recruits him to Alexandria . Daryl and Tara plot to deviate from Rick 's plans by destroying the Sanctuary . Ezekiel isolates himself at the Kingdom , where Carol tries to encourage him to be the leader his people need . Maggie has the group of captured Saviors placed in a holding area and forces Gregory to join them as punishment for betraying Hilltop . 106 7 `` Time for After '' Larry Teng Matthew Negrete & Corey Reed December 3 , 2017 ( 2017 - 12 - 03 ) 7.47 After learning of Dwight 's association with Rick 's group , Eugene affirms his loyalty to Negan and outlines a plan to get rid of the walkers surrounding the Sanctuary . With help from Morgan and Tara , Daryl drives a truck through the Sanctuary 's walls , flooding its interior with walkers , killing many Saviors . Rick finally convinces Jadis and the Scavengers to align with him , and they plan to force the Saviors to surrender . However , when they arrive at the Sanctuary , Rick is horrified to see the breached walls and no sign of the walker herd . 107 8 `` How It 's Gotta Be '' Michael E. Satrazemis David Leslie Johnson & Angela Kang December 10 , 2017 ( 2017 - 12 - 10 ) 7.89 Eugene 's plan allows the Saviors to escape , and separately , the Saviors waylay the Alexandria , Hilltop , and Kingdom forces . The Scavengers abandon Rick , after which he returns to Alexandria . Ezekiel ensures that the Kingdom residents are able to escape before locking himself in the community with the Saviors . Eugene aids Gabriel and Doctor Carson in escaping the Sanctuary in order to ease his conscience . Negan attacks Alexandria , but Carl devises a plan to allow the Alexandria residents to escape into the sewers . Carl reveals he was bitten by a walker while escorting Siddiq to Alexandria . 108 9 `` Honor '' Greg Nicotero Matthew Negrete & Channing Powell February 25 , 2018 ( 2018 - 02 - 25 ) 8.28 After the Saviors leave Alexandria , the survivors make for the Hilltop while Rick and Michonne stay behind to say their final goodbyes to a dying Carl , who pleads with Rick to build a better future alongside the Saviors before killing himself . In the Kingdom , Morgan and Carol launch a rescue mission for Ezekiel . Although they are successful and retake the Kingdom , the Saviors ' lieutenant Gavin is killed by Benjamin 's vengeful brother Henry . 109 10 `` The Lost and the Plunderers '' TBA TBA March 4 , 2018 ( 2018 - 03 - 04 ) TBD 110 11 `` Dead or Alive Or '' TBA TBA March 11 , 2018 ( 2018 - 03 - 11 ) TBD 111 12 `` The Key '' TBA TBA March 18 , 2018 ( 2018 - 03 - 18 ) TBD\n"
     ]
    }
   ],
   "source": [
    "print(answers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-eLIZWWFnIQMTcQkVyPy216CG on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-eLIZWWFnIQMTcQkVyPy216CG on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-eLIZWWFnIQMTcQkVyPy216CG on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-eLIZWWFnIQMTcQkVyPy216CG on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-eLIZWWFnIQMTcQkVyPy216CG on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m \u001b[39mimport\u001b[39;00m VectorDBQA, OpenAI\n\u001b[1;32m      5\u001b[0m embeddings \u001b[39m=\u001b[39m OpenAIEmbeddings()\n\u001b[0;32m----> 6\u001b[0m doc_store \u001b[39m=\u001b[39m Qdrant\u001b[39m.\u001b[39;49mfrom_texts(\n\u001b[1;32m      7\u001b[0m     answers, embeddings, host\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mlocalhost\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m      8\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/langchain/vectorstores/qdrant.py:1123\u001b[0m, in \u001b[0;36mQdrant.from_texts\u001b[0;34m(cls, texts, embedding, metadatas, ids, location, url, port, grpc_port, prefer_grpc, https, api_key, prefix, timeout, host, path, collection_name, distance_func, content_payload_key, metadata_payload_key, vector_name, batch_size, shard_number, replication_factor, write_consistency_factor, on_disk_payload, hnsw_config, optimizers_config, wal_config, quantization_config, init_from, on_disk, force_recreate, **kwargs)\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Construct Qdrant wrapper from a list of texts.\u001b[39;00m\n\u001b[1;32m    989\u001b[0m \n\u001b[1;32m    990\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1089\u001b[0m \u001b[39m        qdrant = Qdrant.from_texts(texts, embeddings, \"localhost\")\u001b[39;00m\n\u001b[1;32m   1090\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m qdrant \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_construct_instance(\n\u001b[1;32m   1092\u001b[0m     texts,\n\u001b[1;32m   1093\u001b[0m     embedding,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1121\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   1122\u001b[0m )\n\u001b[0;32m-> 1123\u001b[0m qdrant\u001b[39m.\u001b[39;49madd_texts(texts, metadatas, ids, batch_size)\n\u001b[1;32m   1124\u001b[0m \u001b[39mreturn\u001b[39;00m qdrant\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/langchain/vectorstores/qdrant.py:178\u001b[0m, in \u001b[0;36mQdrant.add_texts\u001b[0;34m(self, texts, metadatas, ids, batch_size, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Run more texts through the embeddings and add to the vectorstore.\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \n\u001b[1;32m    164\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[39m    List of ids from adding the texts into the vectorstore.\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    177\u001b[0m added_ids \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 178\u001b[0m \u001b[39mfor\u001b[39;00m batch_ids, points \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate_rest_batches(\n\u001b[1;32m    179\u001b[0m     texts, metadatas, ids, batch_size\n\u001b[1;32m    180\u001b[0m ):\n\u001b[1;32m    181\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mupsert(\n\u001b[1;32m    182\u001b[0m         collection_name\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcollection_name, points\u001b[39m=\u001b[39mpoints, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    183\u001b[0m     )\n\u001b[1;32m    184\u001b[0m     added_ids\u001b[39m.\u001b[39mextend(batch_ids)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/langchain/vectorstores/qdrant.py:1669\u001b[0m, in \u001b[0;36mQdrant._generate_rest_batches\u001b[0;34m(self, texts, metadatas, ids, batch_size)\u001b[0m\n\u001b[1;32m   1666\u001b[0m batch_ids \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(islice(ids_iterator, batch_size))\n\u001b[1;32m   1668\u001b[0m \u001b[39m# Generate the embeddings for all the texts in a batch\u001b[39;00m\n\u001b[0;32m-> 1669\u001b[0m batch_embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_embed_texts(batch_texts)\n\u001b[1;32m   1671\u001b[0m points \u001b[39m=\u001b[39m [\n\u001b[1;32m   1672\u001b[0m     rest\u001b[39m.\u001b[39mPointStruct(\n\u001b[1;32m   1673\u001b[0m         \u001b[39mid\u001b[39m\u001b[39m=\u001b[39mpoint_id,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1688\u001b[0m     )\n\u001b[1;32m   1689\u001b[0m ]\n\u001b[1;32m   1691\u001b[0m \u001b[39myield\u001b[39;00m batch_ids, points\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/langchain/vectorstores/qdrant.py:1636\u001b[0m, in \u001b[0;36mQdrant._embed_texts\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m   1625\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Embed search texts.\u001b[39;00m\n\u001b[1;32m   1626\u001b[0m \n\u001b[1;32m   1627\u001b[0m \u001b[39mUsed to provide backward compatibility with `embedding_function` argument.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1633\u001b[0m \u001b[39m    List of floats representing the texts embedding.\u001b[39;00m\n\u001b[1;32m   1634\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1636\u001b[0m     embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membeddings\u001b[39m.\u001b[39;49membed_documents(\u001b[39mlist\u001b[39;49m(texts))\n\u001b[1;32m   1637\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(embeddings, \u001b[39m\"\u001b[39m\u001b[39mtolist\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m   1638\u001b[0m         embeddings \u001b[39m=\u001b[39m embeddings\u001b[39m.\u001b[39mtolist()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/langchain/embeddings/openai.py:472\u001b[0m, in \u001b[0;36mOpenAIEmbeddings.embed_documents\u001b[0;34m(self, texts, chunk_size)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Call out to OpenAI's embedding endpoint for embedding search docs.\u001b[39;00m\n\u001b[1;32m    461\u001b[0m \n\u001b[1;32m    462\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[39m    List of embeddings, one for each text.\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    470\u001b[0m \u001b[39m# NOTE: to keep things simple, we assume the list may contain texts longer\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[39m#       than the maximum context and use length-safe embedding function.\u001b[39;00m\n\u001b[0;32m--> 472\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_len_safe_embeddings(texts, engine\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdeployment)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/langchain/embeddings/openai.py:358\u001b[0m, in \u001b[0;36mOpenAIEmbeddings._get_len_safe_embeddings\u001b[0;34m(self, texts, engine, chunk_size)\u001b[0m\n\u001b[1;32m    355\u001b[0m     _iter \u001b[39m=\u001b[39m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(tokens), _chunk_size)\n\u001b[1;32m    357\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m _iter:\n\u001b[0;32m--> 358\u001b[0m     response \u001b[39m=\u001b[39m embed_with_retry(\n\u001b[1;32m    359\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[1;32m    360\u001b[0m         \u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49mtokens[i : i \u001b[39m+\u001b[39;49m _chunk_size],\n\u001b[1;32m    361\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_invocation_params,\n\u001b[1;32m    362\u001b[0m     )\n\u001b[1;32m    363\u001b[0m     batched_embeddings\u001b[39m.\u001b[39mextend(r[\u001b[39m\"\u001b[39m\u001b[39membedding\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m response[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m    365\u001b[0m results: List[List[List[\u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m [[] \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(texts))]\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/langchain/embeddings/openai.py:107\u001b[0m, in \u001b[0;36membed_with_retry\u001b[0;34m(embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    104\u001b[0m     response \u001b[39m=\u001b[39m embeddings\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    105\u001b[0m     \u001b[39mreturn\u001b[39;00m _check_response(response)\n\u001b[0;32m--> 107\u001b[0m \u001b[39mreturn\u001b[39;00m _embed_with_retry(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tenacity/__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[1;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_f\u001b[39m(\u001b[39m*\u001b[39margs: t\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: t\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mAny:\n\u001b[0;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(f, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tenacity/__init__.py:389\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoSleep):\n\u001b[1;32m    388\u001b[0m     retry_state\u001b[39m.\u001b[39mprepare_for_next_attempt()\n\u001b[0;32m--> 389\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msleep(do)\n\u001b[1;32m    390\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    391\u001b[0m     \u001b[39mreturn\u001b[39;00m do\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tenacity/nap.py:31\u001b[0m, in \u001b[0;36msleep\u001b[0;34m(seconds)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msleep\u001b[39m(seconds: \u001b[39mfloat\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     26\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[39m    Sleep strategy that delays execution for a given number of seconds.\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \n\u001b[1;32m     29\u001b[0m \u001b[39m    This is the default strategy, and may be mocked out for unit testing.\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m     time\u001b[39m.\u001b[39;49msleep(seconds)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Qdrant\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain import VectorDBQA, OpenAI\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "doc_store = Qdrant.from_texts(\n",
    "    answers, embeddings, host=\"localhost\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/langchain/chains/retrieval_qa/base.py:252: UserWarning: `VectorDBQA` is deprecated - please use `from langchain.chains import RetrievalQA`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "llm = OpenAI()\n",
    "qa = VectorDBQA.from_chain_type(\n",
    "    llm = llm,\n",
    "    chain_type = \"stuff\",\n",
    "    vectorstore = doc_store,\n",
    "    return_source_documents = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(52)\n",
    "selected_questions = random.choices(questions, k = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> where do frankenstein and the monster first meet\n",
      " Frankenstein and the monster first meet in the mountains.\n",
      "\n",
      "> who are the actors in fast and furious\n",
      " The Fast and the Furious (2001) stars Vin Diesel as Dominic Toretto, Paul Walker as Brian O'Conner, Michelle Rodriguez as Letty Ortiz, Jordana Brewster as Mia Toretto, Tyrese Gibson as Roman Pearce, and Ludacris as Tej Parker.\n",
      "\n",
      "> properties of red black tree in data structure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-eLIZWWFnIQMTcQkVyPy216CG on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Red black trees are binary search trees with a special property that all nodes are either red or black, the root is black, all leaves are black, and if a node is red, then both its children are black. Every path from a given node to any of its descendant NIL nodes contains the same number of black nodes. The number of black nodes from the root to a node is the node's black depth; the uniform number of black nodes in all paths from root to the leaves is called the black-height of the red-black tree.\n",
      "\n",
      "> who designed the national coat of arms of south africa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-eLIZWWFnIQMTcQkVyPy216CG on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-eLIZWWFnIQMTcQkVyPy216CG on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-eLIZWWFnIQMTcQkVyPy216CG on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-eLIZWWFnIQMTcQkVyPy216CG on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Iaan Bekker's design was chosen.\n",
      "\n",
      "> caravaggio's death of the virgin pamela askew\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-eLIZWWFnIQMTcQkVyPy216CG on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-eLIZWWFnIQMTcQkVyPy216CG on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-eLIZWWFnIQMTcQkVyPy216CG on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I don't know.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for question in selected_questions:\n",
    "    print(\">\", question)\n",
    "    print(qa.run(question), end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_prompt = \"\"\"\n",
    "Use the following pieces of context to answer the question at the end. Please provide\n",
    "a short single-sentence summary answer only. If you don't know the answer or if it's \n",
    "not present in given context, don't try to make up an answer, but suggest me a random \n",
    "unrelated song title I could listen to. \n",
    "Context: {context}\n",
    "Question: {question}\n",
    "Helpful Answer:\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_prompt_template = PromptTemplate(\n",
    "    template = custom_prompt, input_variables = [\"context\",\"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/langchain/chains/retrieval_qa/base.py:252: UserWarning: `VectorDBQA` is deprecated - please use `from langchain.chains import RetrievalQA`\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for VectorDBQA\nvectorstore\n  field required (type=value_error.missing)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m custom_qa \u001b[39m=\u001b[39m VectorDBQA\u001b[39m.\u001b[39;49mfrom_chain_type(\n\u001b[1;32m      2\u001b[0m     llm \u001b[39m=\u001b[39;49m llm,\n\u001b[1;32m      3\u001b[0m     chain_type \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mstuff\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      4\u001b[0m     return_source_documents \u001b[39m=\u001b[39;49m \u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m      5\u001b[0m     chain_type_kwargs \u001b[39m=\u001b[39;49m {\u001b[39m\"\u001b[39;49m\u001b[39mprompt\u001b[39;49m\u001b[39m\"\u001b[39;49m: custom_prompt_template},\n\u001b[1;32m      6\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/langchain/chains/retrieval_qa/base.py:104\u001b[0m, in \u001b[0;36mBaseRetrievalQA.from_chain_type\u001b[0;34m(cls, llm, chain_type, chain_type_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m _chain_type_kwargs \u001b[39m=\u001b[39m chain_type_kwargs \u001b[39mor\u001b[39;00m {}\n\u001b[1;32m    101\u001b[0m combine_documents_chain \u001b[39m=\u001b[39m load_qa_chain(\n\u001b[1;32m    102\u001b[0m     llm, chain_type\u001b[39m=\u001b[39mchain_type, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m_chain_type_kwargs\n\u001b[1;32m    103\u001b[0m )\n\u001b[0;32m--> 104\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m(combine_documents_chain\u001b[39m=\u001b[39;49mcombine_documents_chain, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/langchain/load/serializable.py:74\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 74\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     75\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lc_kwargs \u001b[39m=\u001b[39m kwargs\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pydantic/main.py:341\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for VectorDBQA\nvectorstore\n  field required (type=value_error.missing)"
     ]
    }
   ],
   "source": [
    "custom_qa = VectorDBQA.from_chain_type(\n",
    "    llm = llm,\n",
    "    chain_type = \"stuff\",\n",
    "    vectorstore = doc_store,\n",
    "    return_source_documents = False,\n",
    "    chain_type_kwargs = {\"prompt\": custom_prompt_template},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
